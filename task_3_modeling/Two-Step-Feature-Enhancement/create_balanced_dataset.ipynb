{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ee4aa5",
   "metadata": {},
   "source": [
    "## Create balanced dataset for CRIC\n",
    "\n",
    "Based on the paper: https://doi.org/10.3390/jimaging7070111\n",
    "\n",
    "And source code: https://github.com/debnasser/deep-learning-ensemble-jimaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c25169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "from skimage.util import random_noise\n",
    "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c1a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "SEED = 42\n",
    "IN_MEM = False # Create Test and Train directories instead of reading images in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d5dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASC-H', 'SCC', 'HSIL', 'NILM', 'LSIL', 'ASC-US']\n"
     ]
    }
   ],
   "source": [
    "base_folder = './CRIC_data/'\n",
    "classes = os.listdir(base_folder)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a9a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_dict = {\n",
    "    'ASC-H': 0,\n",
    "    'ASC-US': 1,\n",
    "    'SCC': 2,\n",
    "    'HSIL': 3,\n",
    "    'LSIL': 4,\n",
    "    'NILM': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3cbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opAugmentation(op, img):\n",
    "    if img is None:\n",
    "        print(\"opAug img is None!!\")\n",
    "    # rotation\n",
    "    if(op == 1):\n",
    "        new_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif(op == 2):\n",
    "        new_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "    elif(op == 3):\n",
    "        new_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    # mirror\n",
    "    elif(op == 4):\n",
    "        new_img= cv2.flip(img, 1)\n",
    "    elif(op == 5):\n",
    "        img_rotate_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        new_img = cv2.flip(img_rotate_90, 1)\n",
    "    elif(op == 6):\n",
    "        img_rotate_180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        new_img = cv2.flip(img_rotate_180, 1)\n",
    "    elif(op == 7):\n",
    "        img_rotate_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        new_img = cv2.flip(img_rotate_270, 1)\n",
    "    elif(op == 8):\n",
    "        sigma = 0.05 \n",
    "        noisy = random_noise(img, var=sigma**2)\n",
    "        new_img = noisy\n",
    "        new_img = new_img * 255\n",
    "    elif(op == 9):\n",
    "        sigma = 0.005 \n",
    "        noisy = random_noise(img, var=sigma**2)\n",
    "        new_img = denoise_tv_chambolle(noisy, weight=0.05, multichannel=True)\n",
    "        new_img = new_img * 255\n",
    "    elif(op == 10):\n",
    "        sigma = 0.005 \n",
    "        noisy = random_noise(img, var=sigma**2)\n",
    "        new_img = denoise_bilateral(noisy, sigma_color=0.01, sigma_spatial=5, multichannel=True)\n",
    "        new_img = new_img * 255\n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fa53c",
   "metadata": {},
   "source": [
    "### Create Train and Test directories\n",
    "\n",
    "- Use symbolic links where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e566b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataTest(imgs_test, class_folder, class_id, in_mem = False):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(len(imgs_test)):\n",
    "        if in_mem:\n",
    "            X_test.append(cv2.imread(class_folder + imgs_test[x]))\n",
    "            y_test.append(class_id)\n",
    "        else:\n",
    "            os.symlink('../' + imgs_test[x], class_folder + 'Test/' + imgs_test[x])\n",
    "    return X_test, y_test\n",
    "\n",
    "def dataaugmentationASCH(imgs_train, imgs_test,\n",
    "                         class_folder = base_folder + 'ASC-H/', class_id = class_id_dict['ASC-H'], \n",
    "                         in_mem = IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])\n",
    "        \n",
    "    imgs_selected = random.sample(range(n_imgs), 21) # 24 + 6*21 = 150\n",
    "    for img_sel in imgs_selected:\n",
    "        ops = random.sample(range(1,10), 6)\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        for op in ops:\n",
    "            new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "            if not in_mem:\n",
    "                cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "            else:\n",
    "                X_train_aug.append(new_img)\n",
    "                y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "def dataaugmentationASCUS(imgs_train, imgs_test,\n",
    "                          class_folder = base_folder + 'ASC-US/', class_id = class_id_dict['ASC-US'],\n",
    "                          in_mem = IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])\n",
    "        \n",
    "    imgs_selected = random.sample(range(n_imgs), 35) # 80 + 2*35 = 150\n",
    "    for img_sel in imgs_selected:\n",
    "        ops = random.sample(range(1,10), 2)\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        for op in ops:\n",
    "            new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "            if not in_mem:\n",
    "                cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "            else:\n",
    "                X_train_aug.append(new_img)\n",
    "                y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "def dataaugmentationSCC(imgs_train, imgs_test,\n",
    "                        class_folder = base_folder + 'SCC/', class_id = class_id_dict['SCC'], \n",
    "                        in_mem = IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])\n",
    "        \n",
    "    imgs_selected = random.sample(range(n_imgs), 15) # 16 + 9*15 = 150\n",
    "    for img_sel in imgs_selected:\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        for op in range(1,10):\n",
    "            new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "            if not in_mem:\n",
    "                cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "            else:\n",
    "                X_train_aug.append(new_img)\n",
    "                y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "def dataaugmentationHSIL(imgs_train, imgs_test,\n",
    "                         class_folder = base_folder + 'HSIL/', class_id = class_id_dict['HSIL'], \n",
    "                         in_mem=IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])        \n",
    "        \n",
    "    imgs_selected = random.sample(range(n_imgs), 17) # 19 + 8*17 = 155\n",
    "    for img_sel in imgs_selected:\n",
    "        ops = random.sample(range(1,10), 8)\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        for op in ops:\n",
    "            new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "            if not in_mem:\n",
    "                cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "            else:\n",
    "                X_train_aug.append(new_img)\n",
    "                y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "def dataaugmentationLSIL(imgs_train, imgs_test,\n",
    "                         class_folder = base_folder + 'LSIL/', class_id = class_id_dict['LSIL'],\n",
    "                         in_mem = IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])\n",
    "            \n",
    "    imgs_selected = random.sample(range(n_imgs), 18) # 132 + 1*18 = 150\n",
    "    for img_sel in imgs_selected:\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        op = random.randint(1,10)\n",
    "        new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "        if not in_mem:\n",
    "            cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "        else:\n",
    "            X_train_aug.append(new_img)\n",
    "            y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "def dataaugmentationNILM(imgs_train, imgs_test, \n",
    "                         class_folder = base_folder + 'NILM/', class_id = class_id_dict['NILM'],\n",
    "                         in_mem = IN_MEM):\n",
    "    n_imgs = len(imgs_train)\n",
    "    X_train_aug = []\n",
    "    y_train_aug = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for x in range(n_imgs):\n",
    "        img = cv2.imread(class_folder + imgs_train[x])\n",
    "        X_train_aug.append(img)\n",
    "        y_train_aug.append(class_id)\n",
    "        if not in_mem:\n",
    "            os.symlink('../' + imgs_train[x], class_folder + 'Train/' + imgs_train[x])\n",
    "            \n",
    "    imgs_selected = random.sample(range(n_imgs), 26) # 47 + 4*26 = 151\n",
    "    for img_sel in imgs_selected:\n",
    "        ops = random.sample(range(1,10), 4)\n",
    "        parts = imgs_train[img_sel].split('.')\n",
    "        for op in ops:\n",
    "            new_img = opAugmentation(op, X_train_aug[img_sel])\n",
    "            if not in_mem:\n",
    "                cv2.imwrite(class_folder + 'Train/' + parts[-2] + '_' + str(op) + '.' + parts[-1], new_img)\n",
    "            else:\n",
    "                X_train_aug.append(new_img)\n",
    "                y_train_aug.append(class_id)\n",
    "    X_test, y_test = dataTest(imgs_test, class_folder, class_id)\n",
    "    return X_train_aug, y_train_aug, X_test, y_test\n",
    "\n",
    "fn_class = {\n",
    "    'ASC-H': dataaugmentationASCH,\n",
    "    'ASC-US': dataaugmentationASCUS,\n",
    "    'SCC': dataaugmentationSCC,\n",
    "    'HSIL': dataaugmentationHSIL,\n",
    "    'LSIL': dataaugmentationLSIL,\n",
    "    'NILM': dataaugmentationNILM\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615f5b0",
   "metadata": {},
   "source": [
    "### Process each of the 6 folders in the CRIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b21ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ASC-H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1953243/2745185738.py:31: FutureWarning: `multichannel` is a deprecated argument name for `denoise_tv_chambolle`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  new_img = denoise_tv_chambolle(noisy, weight=0.05, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SCC\n",
      "Processing HSIL\n",
      "Processing NILM\n",
      "Processing LSIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1953243/2745185738.py:36: FutureWarning: `multichannel` is a deprecated argument name for `denoise_bilateral`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  new_img = denoise_bilateral(noisy, sigma_color=0.01, sigma_spatial=5, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ASC-US\n"
     ]
    }
   ],
   "source": [
    "random.seed(SEED) # Ensure reproducibility\n",
    "\n",
    "X_train_aug_bal, y_train_aug_bal = [], []\n",
    "X_val_aug_bal, y_val_aug_bal = [], []\n",
    "X_test_final, y_test_final = [], []\n",
    "\n",
    "for c in classes:\n",
    "    print(\"Processing\", c)\n",
    "    if os.path.isdir(base_folder + c + '/Test/'):\n",
    "        shutil.rmtree(base_folder + c + '/Test/') # remove the Test directory\n",
    "    if os.path.isdir(base_folder + c + '/Train/'):\n",
    "        shutil.rmtree(base_folder + c + '/Train/') # remove the Train directory\n",
    "\n",
    "    imgs = os.listdir(base_folder + c + '/')\n",
    "    imgs_train, imgs_test = train_test_split(imgs, test_size = TEST_SIZE, random_state=SEED)\n",
    "    \n",
    "    if not IN_MEM:\n",
    "        os.makedirs(base_folder + c + '/Train/', exist_ok=True)\n",
    "        os.makedirs(base_folder + c + '/Test/', exist_ok=True)\n",
    "        \n",
    "    X_train_aug, y_train_aug, X_test, y_test = fn_class[c](imgs_train, imgs_test)\n",
    "    X_train_aug, y_train_aug, X_val_aug, y_val_aug = train_test_split(X_train_aug, y_train_aug, \n",
    "                                                                      test_size = TEST_SIZE, random_state=SEED)\n",
    "    X_train_aug_bal = X_train_aug_bal + X_train_aug\n",
    "    y_train_aug_bal = y_train_aug_bal + y_train_aug\n",
    "    X_val_aug_bal = X_val_aug_bal + X_val_aug\n",
    "    y_val_aug_bal = y_val_aug_bal + y_val_aug\n",
    "    X_test_final = X_test_final + X_test\n",
    "    y_test_final = y_test_final + y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed81e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
