{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzwdQlqyft89"
      },
      "source": [
        "# Task 2 Part 1 Pipeline\n",
        "\n",
        "This notebook can be used to combine the images from seperate datasets (currently Mendelay Hussain, CRIC, and CDetector), standardize their names and labels, and split them into train, test, and val directories. No resizing, transformation, or augmentation is being done here.\n",
        "\n",
        "This notebook requires access to module code from models/data and data\n",
        "\n",
        "\n",
        "Author(s): Gaylyn Ruvere using modified pipeline module originally written by Leon Hamnett and Paolo Dano \n",
        "\n",
        "\n",
        "Date: 2022_09_18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw1dgmvxiqop"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD60JcYItHoZ",
        "outputId": "a52cca88-ea54-460e-f56b-02c728a444c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# This step is optional if not using colab and google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajnCnI9broWW"
      },
      "source": [
        "# Customize Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9LJZXBbmK5Rh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c312c15-3f4e-4acf-feda-41424b7eaa96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DrCadx/data/structured/CRIC_Dataset_Structured\n"
          ]
        }
      ],
      "source": [
        "# Customize and write the config.py file\n",
        "# You may need to restart runtime if you run this cell more than once with changes\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Data Paths\n",
        "MY_PATH = '/content/drive/My Drive/DrCadx'\n",
        "DATA_FOLDER = MY_PATH + '/data'\n",
        "\n",
        "# Dataset Paths\n",
        "CRIC_DATASET_PATH = os.path.join(DATA_FOLDER, 'structured', 'CRIC_Dataset_Structured')\n",
        "MEND_DATASET_PATH = os.path.join(DATA_FOLDER, 'raw', 'Image_datasets', 'partner_provided_datasets', 'mendeley_hussain_liquid_based_cytology')\n",
        "CDET_DATASET_PATH = os.path.join(DATA_FOLDER, 'structured', 'CDetector_structured')\n",
        "\n",
        "#ASCY_DATASET_PATH = os.path.join(DATA_FOLDER, 'structured', 'ASCYscraped_structured')\n",
        "#IARC_DATASET_PATH = os.path.join(DATA_FOLDER, 'structured', 'IARCscraped_structured')\n",
        "\n",
        "print(CRIC_DATASET_PATH)\n",
        "\n",
        "# NC Labels\n",
        "CRIC_NC_LABEL = 'NILM'\n",
        "MEND_NC_LABEL = 'NL'\n",
        "CDET_NC_LABEL = 'NILM'\n",
        "ASCY_NC_LABEL = 'NILM'\n",
        "IARC_NC_LABEL = 'NILM' #There actually aren't any in this set\n",
        "\n",
        "# Processed Path\n",
        "CERVAI_PATH = os.path.join(DATA_FOLDER, 'CervAI')\n",
        "#DEST_FOLDER = '/content/gdrive/.shortcut-targets-by-id/1MN_MgyhaHPoUpQYCws4tOpGbXA-NfwN_/Official_Folder_for_CervAi'\n",
        "#DEST_DATA_FOLDER = os.path.join(DEST_FOLDER, 'Data')\n",
        "#CERVAI_PATH = os.path.join(DEST_DATA_FOLDER, 'CervAI_minside300_fixed')\n",
        "METADATA_PATH = os.path.join(CERVAI_PATH, 'MetaData.md')\n",
        "CLASS_LABELS = ['NILM', 'SCC', 'LSIL', 'ASC-US', 'ASC-H', 'HSIL']\n",
        "CLASS_LABELS_NILM = ['NL', 'NILM', 'ACTIN', 'AGC', 'TRICH', 'CAND', 'FLORA', 'HERPS']\n",
        "CLASS_LABELS_OMIT = ['AGC','AGC-FN','AIS','ADC'] # Glandular cells, we don't have enough data to work with them now\n",
        "\n",
        "# Train Test Resources\n",
        "TRAIN_PATH = os.path.join(CERVAI_PATH, 'train')\n",
        "TEST_PATH = os.path.join(CERVAI_PATH, 'test')\n",
        "VAL_PATH = os.path.join(CERVAI_PATH, 'val')\n",
        "SPLIT = [0.8, 0.1, 0.1]\n",
        "\n",
        "\n",
        "# (Over)write the config.py file\n",
        "with open(MY_PATH + '/modules/data/resources/config.py', 'w') as f:\n",
        "    f.write(f\"DATA_FOLDER = '{DATA_FOLDER}'\\n\")\n",
        "    f.write(f\"CRIC_DATASET_PATH = '{CRIC_DATASET_PATH}'\\n\")\n",
        "    f.write(f\"MEND_DATASET_PATH = '{MEND_DATASET_PATH}'\\n\")\n",
        "    f.write(f\"CDET_DATASET_PATH = '{CDET_DATASET_PATH}'\\n\")\n",
        "    f.write(f\"ASCY_DATASET_PATH = '{ASCY_DATASET_PATH}'\\n\")\n",
        "    f.write(f\"IARC_DATASET_PATH = '{IARC_DATASET_PATH}'\\n\")\n",
        "    f.write(f\"CRIC_NC_LABEL = '{CRIC_NC_LABEL}'\\n\")\n",
        "    f.write(f\"MEND_NC_LABEL = '{MEND_NC_LABEL}'\\n\")\n",
        "    f.write(f\"CDET_NC_LABEL = '{CDET_NC_LABEL}'\\n\")\n",
        "    f.write(f\"ASCY_NC_LABEL = '{ASCY_NC_LABEL}'\\n\")\n",
        "    f.write(f\"IARC_NC_LABEL = '{IARC_NC_LABEL}'\\n\")\n",
        "    f.write(f\"CERVAI_PATH = '{CERVAI_PATH}'\\n\")\n",
        "    f.write(f\"METADATA_PATH = '{METADATA_PATH}'\\n\")\n",
        "    f.write(f\"CLASS_LABELS = {CLASS_LABELS}\\n\")\n",
        "    f.write(f\"CLASS_LABELS_NILM = {CLASS_LABELS_NILM}\\n\")\n",
        "    f.write(f\"CLASS_LABELS_OMIT = {CLASS_LABELS_OMIT}\\n\")\n",
        "    f.write(f\"TRAIN_PATH = '{TRAIN_PATH}'\\n\")\n",
        "    f.write(f\"TEST_PATH = '{TEST_PATH}'\\n\")\n",
        "    f.write(f\"VAL_PATH = '{VAL_PATH}'\\n\")\n",
        "    f.write(f\"SPLIT = {SPLIT}\\n\")\n",
        "\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5gkpcSKK5rB"
      },
      "source": [
        "# Combine and generate train/val/test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqn1a3TMqfnL",
        "outputId": "905381dc-0275-431a-878c-3b62acc06205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All datasets present\n",
            "CervAI folder already present, confirm delete existing folder? (y/n) - y\n",
            "Existing Folder deleted\n",
            "Made new cervAi folder...\n",
            "Extracted CRIC paths and labels\n",
            "Extracted MEND paths and labels\n",
            "Extracted CDET paths and labels\n",
            "\n",
            "CervAI Folder Created!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(MY_PATH + '/modules/data')\n",
        "\n",
        "# Import the data pipeline module\n",
        "import ETL_mix_datasets\n",
        "\n",
        "# Combine the datasets\n",
        "ETL_mix_datasets.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bo4dhIgGMxM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}